{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4544b4-c151-4d18-b27f-b66faf49d7fc",
   "metadata": {},
   "source": [
    "<div id=\"colab_button\\\">\n",
    "    <h1>LaVague: Anthropic integration</h1>\n",
    "    <a target=\"_blank\\\" href=\"https://colab.research.google.com/github/lavague-ai/lavague/blob/main/docs/docs/integrations/api/anthropic.ipynb\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is part of our integrations section which shows you how to quickly get started with different LLM integrations. In this notebook, we will use LaVague with Claude via the Anthropic API. The default model used is ```claude-3-haiku-20240307```, but you can also use ```claude-3-sonnet-20240229``` and ```claude-3-opus-20240229``` models by specifying the desired model in the configuration file.\n",
    "\n",
    "**Pre-requisites:**\n",
    "- For our integration notebooks, we assume you have already downloaded the necessary webdriver folders and moved them to your root directory.\n",
    "- For our integration notebooks, we assume you have already downloaded and installed the latest `lavague` package from the `main` of our GitHub repo. For more information on installation - see our [installation guide](../../get-started/setting-up-la-vague) or our [quick tour notebook](../../get-started/quick-tour)\n",
    "- If you are running the notebook locally, you will need Python (tested on python>=3.8) and pip installed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21458260042394af"
  },
  {
   "cell_type": "markdown",
   "id": "a707f0f0-addb-452c-8e03-0d131c1cf51d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "⚠️ For remote inference with the Anthropic API, you will need to provide your Anthropic key in the code block below.\n",
    "\n",
    "> If you don't have an Anthropic API key, you can get one by creating an Anthropic account and following the instructions [here](https://console.anthropic.com/docs/api-keys).  \n",
    "For more detailed information about the Anthropic API, please refer to the [official Anthropic API documentation](https://support.anthropic.com/en/collections/5370014-claude-api)."
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "import os\n",
    "\n",
    "os.environ['ANTHROPIC_API_KEY'] = # ADD YOUR ANTHROPIC API KEY HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafb3178e8ae6e47"
  },
  {
   "cell_type": "markdown",
   "id": "e92fc2ce-09aa-4eff-aaf9-e934b64a716d",
   "metadata": {},
   "source": [
    "### LaVague Launch\n",
    "\n",
    "We will now download the default configuration files for running LaVague with the Anthropic API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb296a5-5cda-4600-b2d3-f2883833f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/lavague-ai/LaVague/main/examples/configurations/api/anthropic_api.py\n",
    "!wget https://raw.githubusercontent.com/lavague-ai/LaVague/main/examples/instructions/huggingface.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a6513-ebaa-45fb-ad8f-46e90cda475b",
   "metadata": {},
   "source": [
    "We can now launch our interactive Gradio which will be created with three default instructions which can be executed on the HuggingFace website as defined in the `huggingface.yaml` file.\n",
    "\n",
    "> Feel free to take a look at the `anthropic_api.py` file to see our default config and play around with different configurations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3657e1-9050-4a86-bc07-f0ca2f26f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lavague -i huggingface.yaml -c anthropic_api.py launch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c047e-6c16-4e03-a0eb-fc8027ad1803",
   "metadata": {},
   "source": [
    "You can now click on the public (if you are using Google Colab) or local URL to open the Gradio in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b49f2-c719-4fc2-9de2-bce6d1aed561",
   "metadata": {},
   "source": [
    "### LaVague Build\n",
    "\n",
    "We can alternatively use the `lavague [OPTIONS] build` command to generate a python script with the Selenium code needed to perform your desired action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f2330-d11b-40b0-8457-28a8f4063fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lavague -i huggingface.yaml -c anthropic_api.py build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408df8d-5190-43ca-86f1-10ab38c257db",
   "metadata": {},
   "source": [
    "This creates a script with the Python code generated by the LLM to perform the desired action in the current directory named `huggingface_anthropic_api_gen.py`.\n",
    "\n",
    "You can now inspect the code or execute it locally!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33125049-fe17-45af-86e0-70bbc7bc890c",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "That brings us to the end of this OpenAI integration demo. \n",
    "\n",
    "If you have any further questions, join us on the LaVague Discord [here](https://discord.com/invite/SDxn9KpqX9)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lavague_env",
   "language": "python",
   "name": "lavague_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
